{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60f9c9ae-9bd1-4694-92ae-9935fd81f0d3",
   "metadata": {},
   "source": [
    "## Task 1 – Import required libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523d6690-d188-40db-b0bb-fac08ab136a1",
   "metadata": {},
   "source": [
    "### Here, we are importing the following required libraries:\n",
    "* csv for writing data to a CSV file\n",
    "* pandas for creating the data elements\n",
    "* selenium for sending HTTP requests to the website\n",
    "* BeautifulSoup for parsing the HTML source code of the webpage\n",
    "* Webdriver_manager for automatated installation and management of web drivers\n",
    "* time for introducing a delay in our program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaeaf55-4795-4d76-bf13-0698c1f44459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae70dc1-900d-4595-b2f7-cb26ebc5f8a2",
   "metadata": {},
   "source": [
    "## Task 2 – Setup the Selenium Webdriver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de80263-bd6d-44eb-ad3d-41dcf1dcb646",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no UI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1410d602-5218-4dce-b054-99cdf871427e",
   "metadata": {},
   "source": [
    "## Task 3 – Generate the functions\n",
    "* Open Indeed in a web browser\n",
    "* Search for jobs based on user input\n",
    "* Scrape and Parse Job postings\n",
    "* Save data into a CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bc4cbe-9ac7-4ca8-a05c-f8a6291bfb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Indeed and Search for Jobs\n",
    "def search_jobs(job_title, location):\n",
    "    url = \"https://ca.indeed.com/\"\n",
    "    driver.get(url)\n",
    "    time.sleep(2)  # Allow time for page to load\n",
    "\n",
    "    # Find search fields\n",
    "    job_search = driver.find_element(By.ID, \"text-input-what\")\n",
    "    location_search = driver.find_element(By.ID, \"text-input-where\")\n",
    "\n",
    "    # Clear and input job title & location\n",
    "    job_search.clear()\n",
    "    job_search.send_keys(job_title)\n",
    "\n",
    "    location_search.clear()\n",
    "    location_search.send_keys(location)\n",
    "\n",
    "    # Press Enter to search\n",
    "    job_search.send_keys(Keys.RETURN)\n",
    "    time.sleep(3)  # Allow results to load\n",
    "\n",
    "\n",
    "# Parse Job Listings\n",
    "def scrape_jobs():\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    job_cards = soup.find_all(\"div\", class_=\"job_seen_beacon\")\n",
    "\n",
    "    jobs = []\n",
    "\n",
    "    for job in job_cards:\n",
    "        title_elem = job.find(\"h2\", class_=\"jobTitle css-1psdjh5 eu4oa1w0\")\n",
    "        company_elem = job.find(\"span\", class_=\"css-1h7lukg eu4oa1w0\")\n",
    "        location_elem = job.find(\"div\", class_=\"css-1restlb eu4oa1w0\")\n",
    "        link_elem = job.find(\"a\", class_=\"jcs-JobTitle css-1baag51 eu4oa1w0\")\n",
    "\n",
    "        if title_elem and company_elem and location_elem and link_elem:\n",
    "            job_title = title_elem.text.strip()\n",
    "            company = company_elem.text.strip()\n",
    "            location = location_elem.text.strip()\n",
    "            job_link = \"https://ca.indeed.com\" + link_elem[\"href\"]\n",
    "\n",
    "            jobs.append([job_title, company, location, job_link])\n",
    "\n",
    "    return jobs\n",
    "\n",
    "\n",
    "# Save Data to CSV\n",
    "def save_to_csv(data, filename=\"indeed_jobs.csv\"):\n",
    "    df = pd.DataFrame(data, columns=[\"Job Title\", \"Company\", \"Location\", \"Job Link\"])\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Data saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9f86d9-7693-4289-8a65-2324a7d5087d",
   "metadata": {},
   "source": [
    "## Task 4 – Define the main function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f961c32-df5d-4df7-a9a3-519ddc3b64e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the script\n",
    "if __name__ == \"__main__\":\n",
    "    job_title = input(\"Enter job title to search: \")\n",
    "    location = input(\"Enter job location (leave blank for Etobicoke as Default): \")  # No default location\n",
    "\n",
    "    search_jobs(job_title, location)\n",
    "    jobs_data = scrape_jobs()\n",
    "\n",
    "    if jobs_data:\n",
    "        save_to_csv(jobs_data)\n",
    "    else:\n",
    "        print(\"No jobs found.\")\n",
    "\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a249c497-01d4-4c1b-90a0-1b656cffef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('indeed_jobs.csv')\n",
    "\n",
    "# Print the dataframe as a table\n",
    "print(tabulate(df, headers='keys'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
